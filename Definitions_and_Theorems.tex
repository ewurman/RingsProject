\documentclass{article}

\usepackage{fancyhdr}
\usepackage{extramarks}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{tikz}
\usepackage[plain]{algorithm}
\usepackage{algpseudocode}
\usepackage[labelsep=none]{caption}

\usetikzlibrary{automata,positioning}
%
% Basic Document Settings
%

\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

\linespread{1.1}

\pagestyle{fancy}
\lhead{\hmwkAuthorName}
\chead{\ClassName: \hmwkTitle}
\rhead{\hmwkDueDate}


%
% Homework Details
%   - Title
%   - Due date
%   - Class
%   - Author
%

\newcommand{\hmwkTitle}{Final Project \textit{Definitions and Theorems}}
\newcommand{\hmwkDueDate}{Spring 2018}
\newcommand{\ClassName}{Math 3702}
\newcommand{\hmwkAuthorName}{\textbf{Erik, Bo, Phillip}}


%
%Helper functions
%
\newcommand{\separate}{\bigskip}
\newcommand{\smallseparate}{\medskip}
\newcommand{\separateprobs}{\vspace{.25in}}


%Math Functions:
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\I}{\mathbb{I}}
\newcommand{\M}{\mathbb{M}}
\newcommand{\F}{\mathbb{F}}

\setlength\parindent{0pt}

\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}

\begin{document}
\begin{definition}{Linear Code}\\An $(n,k)$ \textit{linear code} over a finite field $F$ is a $k$-dimensional subspace $V$ of the vector space \[F^n = \underbrace{F\oplus F\oplus \dots \oplus F}_{\text{$n$ copies}}\]
over $F$. The members of $V$ are called the \textit{code words}. The ratio $k/n$ is called the \textit{information rate} of the code. When $F$ is $\Z_2$, the code is called binary.
\end{definition}

\begin{example}{The Hamming (7,4) Code}\\
Assuming that our message consists of all possible 4-tuples of 0's and 1's (i.e., we wish to send a sequence of 0's and 1's of length 4). Encoding will be done by viewing these messages as four-dimensional vectors over the field $\Z_2$ and multiplying each of the 16 possible messages on the right by the matrix
\[G=\begin{bmatrix}
1&0&0&0&0&1&1\\
0&1&0&0&1&0&1\\
0&0&1&0&1&1&0\\
0&0&0&1&1&1&1
\end{bmatrix}\]
The resulting seven-dimensional vectors are called \textit{code words.} See Table~\ref{tab:hamming(7,4)}.
\begin{table}[ht!]
    \centering
    \begin{tabular}{c c c}
        \hline
        Message & Encoder $G$ & Code Word\\
        \hline
        0000 & $\rightarrow$ & 0000000 \\
        0001 & $\rightarrow$ & 0001111 \\
        0010 & $\rightarrow$ & 0010110 \\
        0100 & $\rightarrow$ & 0100101 \\
        1000 & $\rightarrow$ & 1000011 \\
        1100 & $\rightarrow$ & 1100110 \\
        1010 & $\rightarrow$ & 1010101 \\
        1001 & $\rightarrow$ & 1001100 \\
        0110 & $\rightarrow$ & 0110011 \\
        0101 & $\rightarrow$ & 0101010 \\
        0011 & $\rightarrow$ & 0011001 \\
        1110 & $\rightarrow$ & 1110000 \\
        1101 & $\rightarrow$ & 1101001 \\
        1011 & $\rightarrow$ & 1011010 \\
        0111 & $\rightarrow$ & 0111100 \\
        1111 & $\rightarrow$ & 1111111 \\
    \end{tabular}
    \caption{}
    \label{tab:hamming(7,4)}
\end{table}
\end{example}

\begin{definition}{Hamming Distance, Hamming Weight}\\The \textit{Hamming distance} between two vectors of a vector space is the number of components in which they differ. The \textit{Hamming weight} of a vector is the number of nonzero components of the vector.\\ We will use $d(u,v)$ to denote the Hamming distance between the vectors $u$ and $v$ and wt$(u)$ for the Hamming weight of the vector $u$.
\end{definition}

\begin{definition}{Nearest-Neighbor Decoding}\\
  For any received vector $v$, the corresponding code word sent is a code word $v'$ such that the Hamming distance $d(v,v')$ is a minimum. If there is more than one such $v'$, we decide arbitrarily.
\end{definition}

\begin{theorem}{Properties of Hamming Distance and Hamming Weight}\\
For any vectors $u,v$ and $w$ of a linear code, $d(u,v)\leq d(u,w)+d(w,v)$ and $d(u,v)=wt(u-v)$.
\end{theorem}

\begin{theorem}{Correcting Capability of a Linear Code}\\
If the Hamming weight of every nonzero code word in a linear code is at least $2t+1$, then the code can correct for any $t$ or fewer errors. Furthermore, the same code can detect any $2t$ or fewer errors..
\end{theorem}
\begin{proof}
  Using the nearest-neighbor decoding, suppose a transmitted code word $u$ is received as the vector $v$ and at most $t$ errors were made in transmission. Then, by definition, $d(v,u)\leq t$. If $w$ is any code word other than $u$, then $w-u$ is a nonzero code word. Thus, by assumption,
  \[2t+1 \leq \text{wt}(w-u) = d(w,u) \leq d(w,v) + d(v,u) \leq d(w,v) + t\]
  and it follows that $t+1 \leq d(w,v).$ So the code word closest to the received vector $v$ is $u$ and, therefore $v$ is correctly decoded as u.\\
  To show that the code can detect $2t$ errors, we suppose a transmitted code word $u$ is received as the vector $v$ and at least one error, but no more than $2t$ errors, was made in transmission. Because only code words are transmitted, an error will be detected whenever a received word is not a code word. But, $u$ cannot be a code word, since $d(v,u) \leq 2t$, while we know that the minimum distance between distinct code words is at least $2t+1$.
\end{proof}

\begin{theorem}{Singleton Bound}\\
  Let $C$ be a code of length $n$ over and alphabet of size $q$ with minimum Hamming distance $d$. Then $\log_q(|C|) \leq n-d+1.$
\end{theorem}

\begin{definition}{Maximum Distance Separable code}\\
  A code of length $n$ over an alphabet of size $q$ with $|C| = q^k$ and minimum Hamming distance $d$ satisfying $k=n-d+1$ is said to be a Maximal Distance Separable (MDS) code.
\end{definition}

\begin{theorem}{Sphere Packing Bound}\\
  Let $C$ be a code of length $n$ over alphabet of size $q$ with minimum Hamming distance $2t+1$. Then
  \[|C|\left(\sum_{s=0}^t {n \choose s}(q-1)^s\right)\leq q^n\]
\end{theorem}

\begin{definition}{Perfect Code}\\
  A perfect code is a code $C$ of length $n$ where every vector in $\F_q^n$ is contained in precisely one sphere of radius $t$ centered about a codeword.
\end{definition}

\begin{example}{Perfect Codes}\\
  The following are all prefect codes:
  \begin{itemize}
    \item the codes $C = \F_q^n$
    \item the codes consisting fo exactly one codeword (the zero vector in the case of linear codes)
    \item the binary repetition codes of odd length (i.e., \textbf{1} = 11111, length $n=5$)
    \item the binary codes of odd length consisting of a vector $c$ and the complementary vector $\bar{c}$ with 0's and 1's interchanged.
  \end{itemize}
\end{example}

\begin{theorem}
  If $C$ is a linear code over a ring $R$, the th minimum Hamming distance and the minimum Hamming weight are equal.
\end{theorem}

\begin{definition}{Generator Matrix}\\
  A Generator Matrix is any $k\times n$ matrix $G$ whose rows forma  basis for $C$.
\end{definition}

\begin{definition}{Parity-check Matrix}\\
  A parity-check matrix $H$ is a $(n-k)\times n$ matrix, for a $(n,k)$ code $C$, defined by \[C = \Big\{x\in\F^n_q \,|\, Hx^T = 0\Big\}.\] \textit{Note that $C$ is the kernel of the linear transformation $H$, because a linear code is a subspace of a vector space.}
\end{definition}

\begin{theorem}
  If $G = [I_k \,|\, A]$ is a generator matrix for the $(n,k)$ code $C$ in standard form, then $H = [-A^T \,|\, I_{n-k}]$ is a parity check matrix for $C$.
\end{theorem}

\begin{definition}
  Let $R$ be a finite ring. A linear code $C$ over the alphabet $R$ of length $n$ is a submodule of $R^n$.
\end{definition}
\textit{Note: If $R$ is a field then the linear codes are vector spaces and we have the full force of linear algebra at our disposal!}


\end{document}
